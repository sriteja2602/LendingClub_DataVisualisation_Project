# -*- coding: utf-8 -*-
"""datavizFINAL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xm2HdtN0Bmp5g0bWAZUQ_U1iz04OOxcL
"""

# Commented out IPython magic to ensure Python compatibility.
import warnings
warnings.simplefilter('ignore')
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/gdrive')
data= pd.read_csv('/content/gdrive/My Drive/lending_club_loans.csv')
data.head()

pd.options.display.max_rows=150
missing=data.isnull().sum()
missing_ratio=missing/len(data)
missing_ratio=missing_ratio.reset_index()
missing_ratio=missing_ratio.rename(columns={'index':'feature',0:'missing ratio'})
missing_ratio=missing_ratio.sort_values(by='missing ratio',ascending=False)
missing_ratio[missing_ratio['missing ratio']>=0.2]['feature']

columns=['annual_inc_joint','mo_sin_rcnt_rev_tl_op','inq_fi','total_cu_tl','mo_sin_old_il_acct','bc_util','bc_open_to_buy','avg_cur_bal','acc_open_past_24mths','inq_last_12m','total_rev_hi_lim','all_util','max_bal_bc','open_rv_24m','open_rv_12m','il_util','total_bal_il','mths_since_rcnt_il','open_il_24m','open_il_12m','open_il_6m','open_acc_6m','tot_cur_bal','tot_coll_amt','verification_status_joint','mo_sin_old_rev_tl_op','mo_sin_rcnt_tl','mths_since_last_major_derog','mort_acc','total_bc_limit','total_bal_ex_mort','tot_hi_cred_lim','percent_bc_gt_75','pct_tl_nvr_dlq','num_tl_op_past_12m','num_tl_90g_dpd_24m','num_tl_30dpd','num_tl_120dpd_2m','num_sats','num_rev_tl_bal_gt_0','num_rev_accts','num_op_rev_tl','num_il_tl','num_bc_tl','num_bc_sats','num_actv_rev_tl','num_actv_bc_tl','num_accts_ever_120_pd','mths_since_recent_revol_delinq','mths_since_recent_inq','mths_since_recent_bc_dlq','mths_since_recent_bc','dti_joint','total_il_high_credit_limit','next_pymnt_d','mths_since_last_record','mths_since_last_delinq','desc']

data=data.drop(labels=columns,axis=1)
data.head(5)

ongo_columns=['funded_amnt','funded_amnt_inv','issue_d','pymnt_plan','out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv','total_rec_prncp','policy_code','total_rec_int',
             'total_rec_late_fee','recoveries','collection_recovery_fee','last_pymnt_d','last_pymnt_amnt','last_credit_pull_d']

data=data.drop(labels=ongo_columns,axis=1)
data.info(verbose=False)

data['loan_status'].value_counts()

data.shape

data.columns

target=data['loan_status']
from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(data,target,test_size=0.3)

feature='home_ownership'
xtrain[feature].value_counts()
xtrain[feature]=xtrain[feature].fillna(value="OTHER")
xtrain[feature].value_counts()

x=['rent','mortgage','own','other']
y=[141471,13204,2291,136]
plt.bar(x,y)

print(xtrain['int_rate'].values[:3])

def str_parser(x):
    if '%' in str(x):
        return(float(str(x).replace('%','')))
    return x

xtrain['int_rate']=xtrain['int_rate'].apply(str_parser)
xtrain['revol_util']=xtrain['revol_util'].apply(str_parser)
xtest['int_rate']=xtest['int_rate'].apply(str_parser)
xtest['revol_util']=xtest['revol_util'].apply(str_parser)

xtrain=xtrain.drop(labels='emp_title',axis=1)
xtest=xtest.drop(labels='emp_title',axis=1)

emp_length_mode=xtrain['emp_length'].mode()[0]
xtrain['emp_length']=xtrain['emp_length'].fillna(value=emp_length_mode)
xtest['emp_length']=xtest['emp_length'].fillna(value=emp_length_mode)

xtest['title']=xtest['title'].fillna(value="missing")
xtrain['title']=xtrain['title'].fillna(value="missing")

from sklearn import preprocessing
grade_encoder=preprocessing.LabelEncoder()
data['grade']=xtrain['grade'].fillna('G')
data['grade'].value_counts()
xtrain['grade']=xtrain['grade'].replace(['A','B','C','D','E','F','G'],[0,1,2,3,4,5,6])
xtest['grade']=xtest['grade'].replace(['A','B','C','D','E','F','G'],[0,1,2,3,4,5,6])
xtrain['grade'].head()

xtrain['emp_length'].value_counts()
data['emp_length'].value_counts()
g={'< 1 year':0,'1 year':1,'2 years':2,'3 years':3,'4 years':4,'5 years':5,'6 years':6,'7 years':7,'8 years':8,'9 years':9,'10+ years':10}

xtrain['emp_length']=xtrain['emp_length'].apply(lambda x:g[x])

xtest['emp_length']=xtest['emp_length'].apply(lambda x:g[x])

xtrain['title'].unique()

xtrain['title']=xtrain['title'].apply(str.lower)
xtest['title']=xtest['title'].apply(str.lower)

lists=['debt consolidation','credit card refinancing','business','vacation','home improvement','majar purchase','medical expense','car financing','moving and relocation','home buying','green loan','consolidation']

xtrain['term'].value_counts()
xtrain['term'].replace(["36 months","64 months"],[36,64],inplace=True)
xtrain['term'].value_counts()

data['loan_status'].value_counts()

data['term'].value_counts()

x=['36','60']
y=[31534,11001]
plt.bar(x,y)

df=pd.DataFrame(data,columns=["loan_status","term"])
df.head()

group=df["loan_status"].groupby(df["term"])
group

counts=xtrain.groupby(["loan_status","term"])
a=len(list(counts)[0][1]) #charged off 36 month
a

b=len(list(counts)[1][1])#charged off 60 month
b

xtrain["term"].value_counts()
xtrain["term"].head()

c=22067-2257
d=7707-1698
z=["charged off","remaining"]
x=[a,c]
y=[b,d]
plt.title("loan status of 36 months term")
plt.bar(z,x,color=["red","green"])

plt.title("loan status of 60 months term")
plt.bar(z,y,color=["red","green"])

counts=xtrain.groupby(["loan_status","home_ownership"])
list(counts)
#charged off according to home ownership
x=["mortgage","rent","own","other"]
y=[1624,2001,214,16]
plt.title("charged off based on home ownership")
plt.bar(x,y,color=["yellow","orange","blue","green"])

counts=xtrain.groupby(["loan_status","verification_status"])
list(counts)
x=["Not verified","Source verified","verified"]
y=[1519,1011,1425]
plt.title("charged off based on verification status")
plt.bar(x,y,color=["green","blue","red"])

counts=xtrain.groupby(["loan_status","emp_length"])
list(counts)
x=[0,1,2,3,4,5,6,7,8,9]
y=[450,303,391,392,326,320,235,188,151,106]
plt.title("charged off based on employement length")
plt.bar(x,y)

data['delinq_2yrs'].value_counts()
xtrain['delinq_2yrs']=xtrain['delinq_2yrs'].fillna(0.0)
xtrain['delinq_2yrs'].isnull().sum()
counts=xtrain.groupby(["loan_status","delinq_2yrs"])
list(counts)
x=[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0]
y=[3461,361,96,24,0,9,2,1,1]
plt.bar(x,y)

df=pd.DataFrame(data=xtrain,columns=["loan_status","loan_amnt"])
df_prices = df.groupby("loan_status").agg([np.mean, np.std])
prices=df_prices['loan_amnt']
prices.head()

prices.plot(kind = "barh", y = "mean", legend = False, 
            title = "loan amount")

prices.plot(kind = "barh", y = "mean", legend = False, 
            title = "Average Prices", xerr = "std")

xtrain.columns
#xtrain['earliest_cr_line'].head()

numerical=['last_fico_range_high', 'last_fico_range_low','fico_range_low', 'fico_range_high',"loan_amnt","int_rate","installment","emp_length","annual_inc","dti","delinq_2yrs","inq_last_6mths","open_acc","pub_rec",'revol_bal', 'revol_util', 'total_acc','acc_now_delinq', 'delinq_amnt', 'pub_rec_bankruptcies',]

import seaborn as sns
numerical=numerical
correlation=xtrain[numerical].corr()
fig,ax=plt.subplots(figsize=(16,16))
sns.heatmap(correlation,ax=ax)
plt.show()

column=["loan_status"]
xtrain=xtrain.drop(labels=column,axis=1)

b=[]
for i in ytrain:
    if(i=="Charged Off"):
        b.append(1)
    else:
        b.append(0)
xtrain.dtypes
c=xtrain.columns
c
d=["id","member_id","term","sub_grade","verification_status","url","purpose","title"                          
,"zip_code",                       
"addr_state","earliest_cr_line","initial_list_status","application_type"]

xtrain=xtrain.drop(labels=d,axis=1)
xtrain.dtypes

xtrain=xtrain.drop(labels="home_ownership",axis=1)

from sklearn.impute   import SimpleImputer
xtrain['row_missingness'] = xtrain.isnull().sum(axis=1)
mean_impute  = SimpleImputer(strategy='mean')
imputed_data = mean_impute.fit_transform(xtrain)
imputed_data = pd.DataFrame(imputed_data, columns = xtrain.columns)

column=["loan_status"]
xtest=xtest.drop(labels=column,axis=1)
d=["id","member_id","term","sub_grade","verification_status","url","purpose","title"                          
,"zip_code",                       
"addr_state","earliest_cr_line","initial_list_status","application_type","home_ownership"]

xtest=xtest.drop(labels=d,axis=1)
xtrain.dtypes



from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(imputed_data,b)



from sklearn.impute   import SimpleImputer
xtest['row_missingness'] = xtest.isnull().sum(axis=1)
mean_impute  = SimpleImputer(strategy='mean')
imputed_data2 = mean_impute.fit_transform(xtest)
imputed_data2 = pd.DataFrame(imputed_data2, columns = xtest.columns)

a=lr.predict(imputed_data2)
one=0
zer=0
for i in a:
    if i==1:
        one+=1
    else:
        zer+=1
print(one)
print(zer)

from sklearn.ensemble import RandomForestClassifier 
rf_model = RandomForestClassifier (n_estimators=100,bootstrap = True, max_features = 'sqrt')
rf_model.fit(imputed_data,b)

rf_predictions = rf_model.predict(imputed_data2) 
rf_probs = rf_model.predict_proba(imputed_data2)[:,1]
b1=[]
for i in ytest:
    if (i=='Charged off'):
        b1.append(1)
    else:
        b1.append(0)

from sklearn.metrics import roc_auc_score
#Calculate roc auc
#roc_value = roc_auc_score(b1, rf_probs)
try:
     roc_auc_score(b1, rf_probs)
except ValueError:
    pass

lrpredict=lr.predict(imputed_data2)
from sklearn.metrics import classification_report 
# Accuracy Of Logistic regression
print(classification_report(b1, lrpredict))

plt.plot(b1,lrpredict)

from sklearn.metrics import roc_curve 
lr_pred_prob=lr.predict_proba(imputed_data2)[:,1]
fpr, tpr, Thresholds=roc_curve(b1, lr_pred_prob) 
plt.plot([0,1],[0,1],"k--")
plt.plot(fpr, tpr, Label="Logistic Regression")
plt.xlabel("False positive rate") 
plt.ylabel("True positive rate")
plt.title("Logistiv Regressive ROC curve")

# Accuracy Of Random Forest
print(classification_report(b1,rf_predictions))

fpr1, tpr1,Thresholds =roc_curve(b1,rf_probs)
plt.plot([0,1],[0,1],"k--")
plt.plot(fpr1, tpr1,Label="RandomForest")
plt.xlabel("False positive rate")
plt.ylabel("True positive mate")
plt.title("RandomForest ROC curve")

print(rf_predictions,b1)

plt.plot(rf_predictions,b1)